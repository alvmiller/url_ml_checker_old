{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c7eea2-98eb-4e69-b9bb-f485446e7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dou.ua/forums/topic/56830/\n",
    "# https://www.kaggle.com/datasets/siddharthkumar25/malicious-and-benign-urls?select=urldata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf1e045-7542-4851-ba79-4411e5cc39a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Завантаження датасету у Dataframe (url, result)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"urldata.csv\")\n",
    "if \"url\" not in df.columns or \"result\" not in df.columns:\n",
    "    raise SystemExit(\"CSV must contain 'url' and 'result' columns.\")\n",
    "\n",
    "df[\"result\"] = df[\"result\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d24b056-f47f-4a1c-b2cb-dcb9e4d8af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормалізація URL і безпечний парсинг\n",
    "\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "\n",
    "_SCHEME_RE = re.compile(r'^[a-zA-Z][a-zA-Z0-9+.\\-]*://')\n",
    "\n",
    "def safe_str(u):\n",
    "    \"\"\"Безпечно конвертувати значення в рядок, обробляючи None та NaN.\"\"\"\n",
    "    return \"\" if u is None or (isinstance(u, float) and pd.isna(u)) else str(u)\n",
    "\n",
    "def normalize_url(u: str) -> str:\n",
    "    \"Нормалізує та перевіряє рядок URL-адреси.\"\n",
    "    if u is None or (isinstance(u, float) and pd.isna(u)):\n",
    "        return \"\"\n",
    "\n",
    "    s = str(u).strip().strip('\"\\'')\n",
    "    if not s:\n",
    "        return \"\"\n",
    "\n",
    "    if s.startswith(\"//\"):\n",
    "        s = \"http:\" + s\n",
    "\n",
    "    if not _SCHEME_RE.match(s):\n",
    "        s = \"http://\" + s\n",
    "\n",
    "    return s\n",
    "\n",
    "def safe_urlparse(u: str):\n",
    "    \"\"\"Повертає (scheme, netloc, path, query) і не кидає винятків.\"\"\"\n",
    "    s = normalize_url(u)\n",
    "    try:\n",
    "        p = urlparse(s)\n",
    "        scheme, netloc, path, query = p.scheme or \"\", p.netloc or \"\", p.path or \"\", p.query or \"\"\n",
    "\n",
    "        if not netloc and path:\n",
    "            first, _, rest = path.lstrip(\"/\").partition(\"/\")\n",
    "            if \".\" in first and \" \" not in first:\n",
    "                netloc = first\n",
    "                path = \"/\" + rest if rest else \"\"\n",
    "\n",
    "        return scheme, netloc, path, query\n",
    "    except Exception:\n",
    "        return \"\", \"\", \"\", \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5213826e-7a39-4515-b588-1331a4a4423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Побудова ознак\n",
    "\n",
    "import re\n",
    "from tld import get_tld\n",
    "\n",
    "sstr = lambda i: safe_str(i)\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    \"hostname_length\", \"path_length\", \"fd_length\", \"tld_length\",\n",
    "    \"count-\", \"count@\", \"count?\", \"count%\", \"count.\",\n",
    "    \"count=\", \"count-www\", \"count-digits\", \"count-letters\",\n",
    "    \"count_dir\", \"use_of_ip\", \"short_url\"\n",
    "]\n",
    "\n",
    "def having_ip_address(url):\n",
    "    s = sstr(url)\n",
    "    match = re.search(\n",
    "        r\"(([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.\"\n",
    "        r\"([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\/)|\"\n",
    "        r\"((0x[0-9a-fA-F]{1,2})\\.(0x[0-9a-fA-F]{1,2})\\.(0x[0-9a-fA-F]{1,2})\\.(0x[0-9a-fA-F]{1,2})\\/)|\"\n",
    "        r\"(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}\",\n",
    "        s,\n",
    "    )\n",
    "    return 1 if match else 0\n",
    "\n",
    "def fd_length(url):\n",
    "    path = safe_urlparse(url)[2]\n",
    "    parts = [p for p in path.split(\"/\") if p]\n",
    "    return len(parts[0]) if parts else 0\n",
    "\n",
    "def shortening_service(url):\n",
    "    s = sstr(url).lower()\n",
    "    match = re.search(\n",
    "        r\"(bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\"\n",
    "        r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\"\n",
    "        r\"short\\.to|budurl\\.com|ping\\.fm|post\\.ly|just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\"\n",
    "        r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|lnkd\\.in|\"\n",
    "        r\"db\\.tt|qr\\.ae|adf\\.ly|bitly\\.com|cur\\.lv|q\\.gs|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|\"\n",
    "        r\"buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|\"\n",
    "        r\"vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|link\\.zip\\.net)\",\n",
    "        s,\n",
    "    )\n",
    "    return 1 if match else 0\n",
    "\n",
    "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"url_length\"] = df[\"url\"].apply(lambda i: len(safe_str(i)))\n",
    "    df[\"hostname_length\"] = df[\"url\"].apply(lambda i: len(safe_urlparse(i)[1]))\n",
    "    df[\"path_length\"]     = df[\"url\"].apply(lambda i: len(safe_urlparse(i)[2]))\n",
    "    df[\"fd_length\"]       = df[\"url\"].apply(fd_length)\n",
    "\n",
    "    df[\"tld\"] = df[\"url\"].apply(lambda i: get_tld(normalize_url(i), fail_silently=True))\n",
    "    df[\"tld_length\"] = df[\"tld\"].apply(lambda t: len(t) if isinstance(t, str) and t else -1)\n",
    "    df.drop(columns=[\"tld\"], inplace=True)\n",
    "\n",
    "    # sstr = lambda i: safe_str(i)\n",
    "    df[\"count-\"]      = df[\"url\"].apply(lambda i: sstr(i).count(\"-\"))\n",
    "    df[\"count@\"]      = df[\"url\"].apply(lambda i: sstr(i).count(\"@\"))\n",
    "    df[\"count?\"]      = df[\"url\"].apply(lambda i: sstr(i).count(\"?\"))\n",
    "    df[\"count%\"]      = df[\"url\"].apply(lambda i: sstr(i).count(\"%\"))\n",
    "    df[\"count.\"]      = df[\"url\"].apply(lambda i: sstr(i).count(\".\"))\n",
    "    df[\"count=\"]      = df[\"url\"].apply(lambda i: sstr(i).count(\"=\"))\n",
    "    df[\"count-www\"]   = df[\"url\"].apply(lambda i: sstr(i).lower().count(\"www\"))\n",
    "    df[\"count-digits\"]  = df[\"url\"].apply(lambda i: sum(ch.isdigit() for ch in sstr(i)))\n",
    "    df[\"count-letters\"] = df[\"url\"].apply(lambda i: sum(ch.isalpha() for ch in sstr(i)))\n",
    "    df[\"count_dir\"]     = df[\"url\"].apply(lambda i: safe_urlparse(i)[2].count(\"/\"))\n",
    "    df[\"use_of_ip\"]     = df[\"url\"].apply(having_ip_address)\n",
    "    df[\"short_url\"]     = df[\"url\"].apply(shortening_service)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = build_features(df)\n",
    "missing = [c for c in FEATURE_COLS if c not in df.columns]\n",
    "\n",
    "if missing:\n",
    "    raise SystemExit(f\"Missing feature columns after feature engineering: {missing}\")\n",
    "\n",
    "X = df[FEATURE_COLS]\n",
    "y = df[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "270fed7a-debd-4c0a-9255-1cf9180fc1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Розподіл даних на train/test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52882917-7601-42c4-8ddc-b515d5bd9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Навчання моделей: DecisionTree, LogisticRegression, RandomForest\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "dt_model  = DecisionTreeClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "base_rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced_subsample\",\n",
    ")\n",
    "\n",
    "rf_model = CalibratedClassifierCV(\n",
    "    base_rf,\n",
    "    cv=3,\n",
    "    method=\"sigmoid\"\n",
    ")\n",
    "\n",
    "log_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver=\"lbfgs\",\n",
    "    class_weight=\"balanced\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b000f0-8595-4c35-8ac0-03e619c10f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== decision_tree ===\n",
      "Accuracy: 0.973351202861099\n",
      "Confusion matrix:\n",
      " [[101941   1781]\n",
      " [  1818  29513]]\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.983     0.983    103722\n",
      "           1      0.943     0.942     0.943     31331\n",
      "\n",
      "    accuracy                          0.973    135053\n",
      "   macro avg      0.963     0.962     0.963    135053\n",
      "weighted avg      0.973     0.973     0.973    135053\n",
      "\n",
      "ROC-AUC: 0.9622\n",
      "Saved: model_saved\\decision_tree.joblib\n"
     ]
    }
   ],
   "source": [
    "# Оцінка якості (Accuracy, Precision/Recall/F1, ROC-AUC)\n",
    "\n",
    "import os, json, joblib\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "outdir = \"model_saved\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "def train_eval(name, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]) if hasattr(model, \"predict_proba\") else None\n",
    "    except:\n",
    "        auc = None\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Report:\\n\", classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    if auc is not None:\n",
    "        print(\"ROC-AUC:\", round(auc, 4))\n",
    "\n",
    "    out_path = os.path.join(outdir, f\"{name}.joblib\")\n",
    "    joblib.dump(model, out_path)\n",
    "    print(f\"Saved: {out_path}\")\n",
    "\n",
    "train_eval(\"decision_tree\", dt_model)\n",
    "train_eval(\"random_forest\", rf_model)\n",
    "train_eval(\"log_regression\", log_model)\n",
    "\n",
    "with open(os.path.join(outdir, \"features.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"feature_cols\": FEATURE_COLS}, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbff87-6b08-4606-8531-5ef0d9bb81b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Підсумкова оцінка\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e484ef-a179-474a-a594-9ca090110e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
